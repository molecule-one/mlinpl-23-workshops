{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Schedule\n",
        "\n",
        "1. [~30 min] Intro presentation\n",
        "2. [~60 min] Chapter 1 & 2 (Random & Mutate Loop)\n",
        "3. [~15 min] Break\n",
        "4. [~10 min] Discussion on warmup & compound difference\n",
        "5. [~60 min] Chapter 3 (ML, ML Loop)\n",
        "6. [~30 min] Chapter 4: Sending your best solution\n",
        "7. [~15 min] Quick presentation by best performing solution"
      ],
      "metadata": {
        "id": "n5zlEVE6zm3_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-pnBT7gi4WJ"
      },
      "source": [
        "# Chapter 1: Random Screening In Known Compounds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nry0TOx8i4WL"
      },
      "source": [
        "### 📝 Meet our team\n",
        "\n",
        "You were selected to be a lead medicinal chemist in a critical drug discovery project for our company. Your goal is to find a novel GSK3β inhibitor, which could be used to treat cancer. Your first idea is to buy a lot of diverse molecules found in the ZINC database and verify their biological activity in the lab. ZINC is one of the databases in which you can find small molecules that are available for purchase. Some other databases offer even more molecules that can be synthesized on demand. Let's select a random batch of molecules for testing to get started!\n",
        "\n",
        "<img src=\"https://github.com/molecule-one/mlinpl-23-workshops/blob/main/assets/lab1.png?raw=true\" width=\"400px\" />\n",
        "\n",
        "### 📘 Glossary\n",
        "\n",
        "*Dopamine Receptor D$_2$ (DRD2)* - a G protein-coupled receptor that binds dopamine; a common target for antipsychotic drugs.\n",
        "\n",
        "*Glycogen synthase kinase-3 beta (GSK3β)* - an enzyme that can be targeted to treat cancer.\n",
        "\n",
        "*High-throughput screening (HTS)* - an experiment in which biological activity is tested automatically for many compounds in parallel.\n",
        "\n",
        "*Inhibitor* - a molecule that blocks (inhibits) its biological target (usually a protein).\n",
        "\n",
        "*Library* - a collection of molecules\n",
        "\n",
        "*Medicinal chemistry* - a branch of chemistry that investigates the interactions between small molecules (or other compounds with potential therapeutic effects) and their biological targets, e.g. to learn how drugs work in the organism; this knowledge is often used to propose new molecules as drug candidates.\n",
        "\n",
        "*Virtual screening (VS)* - an application of computational tools for finding active compounds in big virtual libraries of compounds.\n",
        "\n",
        "*ZINC* - a database of readily purchasable compounds that can be used for virtual screening."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚒️ Setup & Imports"
      ],
      "metadata": {
        "id": "RdexFKami8rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyTDC rdkit dataclasses_json mols2grid selfies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o9XUNNdUcqkX",
        "outputId": "9327c627-ffd4-4b5e-c9eb-bce5093c193a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyTDC\n",
            "  Downloading PyTDC-0.4.1.tar.gz (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses_json\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting mols2grid\n",
            "  Downloading mols2grid-2.0.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting selfies\n",
            "  Downloading selfies-2.1.1-py3-none-any.whl (35 kB)\n",
            "Collecting rdkit-pypi (from PyTDC)\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fuzzywuzzy (from PyTDC)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from PyTDC) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from PyTDC) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from PyTDC) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from PyTDC) (1.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from PyTDC) (0.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from PyTDC) (2.31.0)\n",
            "Collecting huggingface_hub (from PyTDC)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses (from PyTDC)\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses_json)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses_json)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: ipywidgets<8,>=7 in /usr/local/lib/python3.10/dist-packages (from mols2grid) (7.7.1)\n",
            "Requirement already satisfied: jinja2>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from mols2grid) (3.1.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->mols2grid) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->mols2grid) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->mols2grid) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->mols2grid) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->mols2grid) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->mols2grid) (3.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.0->mols2grid) (2.1.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses_json) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses_json)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses_json) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->PyTDC) (3.12.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->PyTDC) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->PyTDC) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PyTDC) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PyTDC) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->PyTDC) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->PyTDC) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->PyTDC) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->PyTDC) (2023.7.22)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->PyTDC) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->PyTDC) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->PyTDC) (3.2.0)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->PyTDC) (3.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->mols2grid) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->mols2grid) (6.3.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7->mols2grid) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets<8,>=7->mols2grid)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7->mols2grid) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7->mols2grid) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7->mols2grid) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7->mols2grid) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7->mols2grid) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7->mols2grid) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8,>=7->mols2grid) (4.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->PyTDC) (1.16.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8,>=7->mols2grid) (0.8.3)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (5.4.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (0.17.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8,>=7->mols2grid) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<8,>=7->mols2grid) (0.2.8)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (3.11.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (0.8.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (2.18.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (4.19.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (0.10.6)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (1.6.4)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (1.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->mols2grid) (2.21)\n",
            "Building wheels for collected packages: PyTDC\n",
            "  Building wheel for PyTDC (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyTDC: filename=PyTDC-0.4.1-py3-none-any.whl size=140644 sha256=61cc235839ffcc80d79d53b59c54f955bb518811d9a01f031120bc0b9f7e92a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/b7/b8/9d9e1442129743359b0507234ccc0beb67b47173faccd57d54\n",
            "Successfully built PyTDC\n",
            "Installing collected packages: fuzzywuzzy, dataclasses, selfies, rdkit-pypi, rdkit, mypy-extensions, marshmallow, jedi, typing-inspect, huggingface_hub, dataclasses_json, PyTDC, mols2grid\n",
            "Successfully installed PyTDC-0.4.1 dataclasses-0.6 dataclasses_json-0.6.1 fuzzywuzzy-0.18.0 huggingface_hub-0.18.0 jedi-0.19.1 marshmallow-3.20.1 mols2grid-2.0.0 mypy-extensions-1.0.0 rdkit-2023.9.1 rdkit-pypi-2022.9.5 selfies-2.1.1 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "import rdkit"
      ],
      "metadata": {
        "id": "FIx69--qnoVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/molecule-one/mlinpl-23-workshops"
      ],
      "metadata": {
        "id": "ygWPqR3-jChn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265d13fc-f9aa-42b5-d15f-22cc6006d0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mlinpl-23-workshops'...\n",
            "remote: Enumerating objects: 359, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (230/230), done.\u001b[K\n",
            "remote: Total 359 (delta 197), reused 281 (delta 119), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (359/359), 4.87 MiB | 19.62 MiB/s, done.\n",
            "Resolving deltas: 100% (197/197), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"mlinpl-23-workshops\")"
      ],
      "metadata": {
        "id": "SPT0EENjjS0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git pull origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POgkqYhsdGPs",
        "outputId": "f77aca4f-0aa2-4a37-c4d6-e682413f8f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/molecule-one/mlinpl-23-workshops\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚒️ Global Variables"
      ],
      "metadata": {
        "id": "buG9G8JfEKNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SERVER_URL = \"http://mlinpl23.ngrok.io\"\n",
        "YOUR_TOKEN = ???  ### TODO: Paste your token here (from here https://docs.google.com/spreadsheets/d/1ATIJEr1Qn8ZNLffIu_0D5rRimai4n8jw/edit#gid=1107178992)"
      ],
      "metadata": {
        "id": "Ec-H-upsEOX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xirzIM2i4WL"
      },
      "source": [
        "### ⚒️ Exercise 1 Warmup: Requesting your first HTS experiment and achieve 28% score on GSK3B\n",
        "\n",
        "Your task is to find early leads for GSK: achieving at least 28%. It will likely require tuning the budget of your experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG-OWJQVi4WM"
      },
      "outputs": [],
      "source": [
        "# 1. Sample random compounds from the ZINC dataset\n",
        "\n",
        "from src.compound_spaces import SmallZINC\n",
        "from src.organic import show_molecules\n",
        "\n",
        "budget = 500\n",
        "library = SmallZINC()\n",
        "candidates = library.sample(budget)\n",
        "candidates_smiles = [rdkit.Chem.MolToSmiles(mol) for mol in candidates]\n",
        "show_molecules(candidates)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Request running HTS on the selected compounds\n",
        "from src.al_loop import Loop, LeadCompound\n",
        "from src.server_wrapper import FlaskAppClient\n",
        "\n",
        "loop = Loop(base_dir=\".\", user_token=YOUR_TOKEN, target=\"GSK3β_server\")\n",
        "client = FlaskAppClient(base_url=SERVER_URL)\n",
        "\n",
        "tested_molecules = loop.test_in_lab_and_save([LeadCompound(smiles=s) for s in set(candidates_smiles)], client=client)\n",
        "show_molecules(tested_molecules)"
      ],
      "metadata": {
        "id": "J2V1Wo3ykidp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ccPr3pki4WN"
      },
      "outputs": [],
      "source": [
        "# 3. Show the summary of the screening results\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.DataFrame({'Activity': [mol.activity for mol in tested_molecules]})\n",
        "sns.histplot(data, binrange=(-1, 1), binwidth=0.01, x='Activity', log=True) # -1 corresponds to nonsynthesizable compounds\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Go to the leaderboard at https://mlinpl23.ngrok.io/leaderboard: can you see your result?"
      ],
      "metadata": {
        "id": "E2JO3PFNn3lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Code up random loop and run it!\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from typing import List\n",
        "from rich.console import Console\n",
        "import numpy as np\n",
        "console = Console()\n",
        "\n",
        "class RandomLoop(Loop):\n",
        "    \"\"\"Samples random compounds from the ZINC database.\"\"\"\n",
        "    def __init__(self, base_dir: Path, user_token=None, target=\"GSK3β_server\"):\n",
        "        self.space = SmallZINC()\n",
        "        super().__init__(base_dir, user_token, target)\n",
        "    def propose_candidates(self, n_candidates: int) -> List[LeadCompound]:\n",
        "        smi = []\n",
        "\n",
        "        ### TODO: Create a list of randomly sampled SMILES strings.\n",
        "        ### Hint: You can use code above.\n",
        "\n",
        "        ### START SOLUTION\n",
        "        while len(smi) != n_candidates:\n",
        "            sampled_smi = self.space.try_sample()[0]\n",
        "            if sampled_smi not in smi:\n",
        "                smi.append(sampled_smi)\n",
        "\n",
        "        ### END SOLUTION\n",
        "\n",
        "        return [\n",
        "            LeadCompound(s, None, None) for s in smi\n",
        "        ]"
      ],
      "metadata": {
        "id": "MPtgJhQVouTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's define a running function\n",
        "def run(loop, budget=1000, purge=False, steps=10):\n",
        "    target = loop.target\n",
        "    user_token = loop.user_token\n",
        "\n",
        "    if purge:\n",
        "        shutil.rmtree(loop.base_dir, ignore_errors=True)\n",
        "\n",
        "    os.makedirs(loop.base_dir, exist_ok=True)\n",
        "\n",
        "    if target == \"GSK3β\":\n",
        "        client = None\n",
        "    else:\n",
        "        client = FlaskAppClient(SERVER_URL)\n",
        "\n",
        "    if loop.n_iterations > 0:\n",
        "        raise ValueError(f\"Already run. Please remove the folder {loop.base_dir} to run again.\")\n",
        "\n",
        "    metrics = []\n",
        "    all_result: List[LeadCompound] = []\n",
        "    budget_per_step = budget // steps\n",
        "    assert budget % steps == 0 # for simplicity\n",
        "    for step in range(steps):\n",
        "        console.print(f\"[red]Step {step}[/red]\")\n",
        "        candidates = loop.propose_candidates(budget_per_step)\n",
        "        loop.test_in_lab_and_save(candidates, client=client)\n",
        "        result: List[LeadCompound] = loop.load(iteration_id=step)\n",
        "        all_result += result\n",
        "        loop.generate_visualization(iteration_id=step)\n",
        "        all_result_sorted = sorted(all_result, key=lambda x: x.activity, reverse=True)\n",
        "        metrics.append({\"top10\": np.mean([x.activity for x in all_result_sorted[:10]]),\n",
        "                        \"top10_synth\": np.mean([x.synth_score for x in all_result_sorted[:10]])})\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "ytcXfWotq5QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loop = RandomLoop(base_dir=\"random\", user_token=YOUR_TOKEN, target=\"GSK3β_server\")\n",
        "metrics = run(loop, purge=True, budget=1000, steps=10)"
      ],
      "metadata": {
        "id": "Ok41aeh5qiWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. plot metrics using matplotlib\n",
        "plt.plot([i*100 for i in range(len(metrics))],\n",
        "          [m['top10'] for m in metrics], linewidth=4)\n",
        "plt.grid()\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "plt.xlabel('N_compounds')\n",
        "plt.ylabel('top10')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hFzlC1JirBIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. This assert should work now!\n",
        "assert metrics[-1]['top10'] > 0.25 # should match baseline-random on GSK"
      ],
      "metadata": {
        "id": "aGZ_rhAUo_nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p4SqMWti4WN"
      },
      "source": [
        "# Chapter 2: Go Beyond Known Compounds with Mutation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlAZiZcWi4WO"
      },
      "source": [
        "### 📝 Optimize the discovery process\n",
        "\n",
        "Our initial screening campaign produced some positive results, but unfortunately, your manager is not satisfied with the cost-to-success ratio. A lot of money was spent on buying compounds and running biochemical assays, but only a few new compounds were found. It is crucial to optimize this process before the company runs out of funding. One possible solution is to use the already tested compounds to build a QSAR model that can aid in your search. Additionally, you can consider modifying the existing compounds to find similar compounds with better activity.\n",
        "\n",
        "### 📘 Glossary\n",
        "\n",
        "*Biochemical assay* - a test or an analytical procedure that measures protein binding or activity.\n",
        "\n",
        "*ChEMBL* - a public database of molecule activity sourced from publications and patents.\n",
        "\n",
        "*Molecular fingerprint* - a binary vector that encodes fragments that are included in the molecule; the fragments can be predefined or extracted automatically, e.g. by enumerating substructures around each atom of the molecule.\n",
        "\n",
        "*Molecular graph* - a graph representation of a molecule, in which atoms are nodes and chemical bonds are edges, attributed with atom features that encode atom types (carbon, oxygen, nitrogen, etc.) and other atomic properties.\n",
        "\n",
        "*QSAR* - quantitative structure-activity relationship; the name used to describe machine-learning models that predict activity based on the chemical structures at the input.\n",
        "\n",
        "*Random forest* - a machine-learning model that produces its predictions by combining predictions of multiple decision trees constructed based on the input data; single decision trees perform a sequence of decisions on the input features to maximally separate different data classes (in our case, molecules with different activity labels).\n",
        "\n",
        "*SELFIES* - a string representation of a molecule that was designed to work better with machine learning algorithms, e.g. by simplifying the grammar of possible molecules compared to SMILES strings and reducing the number of invalid structures.\n",
        "\n",
        "*SMILES* - a string representation of a molecule that is commonly used to store chemical formulas in databases; in this representation, all atoms of the molecule are encoded by traversing the molecular graph using the DFS order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8dei92Ti4WO"
      },
      "source": [
        "### ⚒️ Exercise 2: Achieve >40% on GSK by exploring mutated compounds\n",
        "\n",
        "<image of zombie>\n",
        "\n",
        "Now we need to introduce a method that can optimize our molecules by introducing small structure modifications. We will use the SELFIES representation of molecules (linearized textual representation) that can be easily modified by changing some letters in the representation code. For example, we can change atoms by replacing their symbols in the SELFIES string. We can also add more atoms by adding symbols in the middle of the sequence.\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/molecule-one/mlinpl-23-workshops/blob/main/assets/lab4.png?raw=true\" width=\"400px\" />"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selfies import encoder, decoder\n",
        "import numpy as np\n",
        "from src.mutate import mutate_selfie\n",
        "from src.al_loop import LeadCompound\n",
        "from src.organic import evaluate_synthesizability"
      ],
      "metadata": {
        "id": "jlfFXNzwt9VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# found max activity\n",
        "all_random_molecules = sum([loop.load(iteration_id=i) for i in range(loop.n_iterations)], [])\n",
        "max([m.activity for m in all_random_molecules])"
      ],
      "metadata": {
        "id": "u3cZFt3_xGde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFBq78-Bi4WO"
      },
      "outputs": [],
      "source": [
        "mutate_top_k = 10\n",
        "n_candidates = 100\n",
        "\n",
        "### TODO: Get top k molecules with the best activity (as SELFIES)\n",
        "### Hint: To encode SELFIES use `encoder(smiles)`\n",
        "selfies = [...]\n",
        "\n",
        "new_compounds = []\n",
        "### TODO: Generate `n_candidates` new compounds by mutating top k molecules.\n",
        "### Hint: To get SMILES of a mutated SELFIES use `decoder(mutate_selfie(selfies, max_molecules_len=100)[0])`\n",
        "assert len(new_compounds) == n_candidates\n",
        "\n",
        "loop = Loop(base_dir=\".\", user_token=YOUR_TOKEN, target=\"GSK3β_server\")\n",
        "client = FlaskAppClient(base_url=SERVER_URL)\n",
        "\n",
        "tested_molecules = loop.test_in_lab_and_save([LeadCompound(smiles=s) for s in set(new_compounds)], client=client)\n",
        "show_molecules(tested_molecules)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Show the summary of the screening results\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.DataFrame({'Activity': [mol.activity for mol in all_random_molecules]})\n",
        "sns.histplot(data, binrange=(-1, 1), binwidth=0.01, x='Activity', log=True, color=\"blue\", label=\"Random\") # -1 corresponds to nonsynthesizable compounds\n",
        "\n",
        "data2 = pd.DataFrame({'Activity': [mol.activity for mol in tested_molecules ]})\n",
        "sns.histplot(data2, binrange=(-1, 1), binwidth=0.01, x='Activity', log=True, color=\"red\", label=\"Mutate\") # -1 corresponds to nonsynthesizable compounds\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9SrY0XUsvwpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Implement mutation loop\n",
        "\n",
        "class MutateLoop(Loop):\n",
        "    \"\"\"Implementation of AL algorithm that mutates top compounds from the previous iterations.\n",
        "\n",
        "       Mutate loop should first search random and then mutate top compounds\n",
        "    \"\"\"\n",
        "    def __init__(self, base_dir: Path, n_warmup_iterations: int = 1, mutate_top_k: int = 10, user_token=None, target=\"DRD2\"):\n",
        "        self.space = SmallZINC()\n",
        "        self.n_warmup_iterations = n_warmup_iterations\n",
        "        self.mutate_top_k = mutate_top_k\n",
        "        super().__init__(base_dir, user_token, target)\n",
        "\n",
        "    def _propose_random(self, n_candidates: int) -> List[LeadCompound]:\n",
        "        smi = [self.space.try_sample()[0] for _ in range(n_candidates)]\n",
        "        return [\n",
        "            LeadCompound(s, None, None) for s in smi\n",
        "        ]\n",
        "\n",
        "    def propose_candidates(self, n_candidates: int) -> List[LeadCompound]:\n",
        "        previous_results: List[LeadCompound] = self.load()\n",
        "\n",
        "        if n_candidates < self.mutate_top_k:\n",
        "            raise ValueError(f\"n_candidates must be at least mutate_top_k ({self.mutate_top_k}).\")\n",
        "\n",
        "        if n_candidates == 0:\n",
        "            return []\n",
        "\n",
        "        if self.n_iterations < self.n_warmup_iterations:\n",
        "            return self._propose_random(n_candidates)\n",
        "\n",
        "        ### TODO: Implement mutation of top k compounds.\n",
        "        ### Hint: You should have this part implemented above.\n",
        "\n",
        "        ### START SOLUTION\n",
        "\n",
        "        topK_ids = np.argsort([c.activity for c in previous_results])[-self.mutate_top_k:]\n",
        "        console.log(\"Mutating top compounds:\")\n",
        "        for i in topK_ids:\n",
        "            console.log(previous_results[i])\n",
        "        selfies = [encoder(previous_results[i].smiles) for i in topK_ids]\n",
        "        m = n_candidates // self.mutate_top_k + 1\n",
        "        new_compounds = []\n",
        "        for i in range(self.mutate_top_k):\n",
        "            new_smiles = []\n",
        "            m_target = min(m, n_candidates - len(new_compounds)) # last batch might be smaller\n",
        "            while len(new_smiles) != m_target:\n",
        "                if len(new_compounds) == n_candidates:\n",
        "                    break\n",
        "                new_smi = decoder(mutate_selfie(selfies[i], max_molecules_len=100)[0])\n",
        "                if new_smi not in new_smiles and new_smi not in new_compounds:\n",
        "                    new_smiles.append(new_smi)\n",
        "            new_compounds += new_smiles\n",
        "\n",
        "        #### END SOLUTION\n",
        "\n",
        "        assert len(new_compounds) == n_candidates\n",
        "        return [LeadCompound(smiles=c) for c in new_compounds]"
      ],
      "metadata": {
        "id": "LxuzZPHMx67C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Run mutation loop\n",
        "mloop = MutateLoop(base_dir=\"mutate\", user_token=YOUR_TOKEN, target=\"GSK3β_server\")\n",
        "mutate_metrics = run(mloop, purge=True, budget=1000, steps=10)"
      ],
      "metadata": {
        "id": "062uAbWOx-wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Plot metrics using matplotlib\n",
        "plt.plot([i*100 for i in range(len(mutate_metrics))],\n",
        "          [m['top10'] for m in mutate_metrics], linewidth=4, label=\"mutate\")\n",
        "plt.plot([i*100 for i in range(len(metrics))],\n",
        "          [m['top10'] for m in metrics], linewidth=4, label=\"random\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "plt.xlabel('N_compounds')\n",
        "plt.ylabel(\"Top 10\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tp_48HOAyUfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. This assert should work now!\n",
        "assert mutate_metrics[-1]['top10'] > 0.3 # should match baseline-random on GSK"
      ],
      "metadata": {
        "id": "qnIsXhZWyYk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Check your performance on leaderboard. Do you see score > 0.4?"
      ],
      "metadata": {
        "id": "UKaa8VoZzPzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📝 Report your new findings\n",
        "\n",
        "Congratulations! You found several novel molecules that are very promising! Now, you need to convince the stakeholders that your approach is highly efficient. Let's compare our new hits with random molecules sampled from ZINC"
      ],
      "metadata": {
        "id": "12hjndoh0TSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Compare random and mutate. What do you observe?\n",
        "\n",
        "top100_random = list(sorted(sum([loop.load(iteration_id=i) for i in range(loop.n_iterations)], []), key=lambda k: -k.activity))[0:100]\n",
        "show_molecules(top100_random)"
      ],
      "metadata": {
        "id": "S_TYOGaDzYXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top100_mutate = list(sorted(sum([mloop.load(iteration_id=i) for i in range(mloop.n_iterations)], []), key=lambda k: -k.activity))[0:100]\n",
        "show_molecules(top100_mutate)"
      ],
      "metadata": {
        "id": "1PWrG7qk2dR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the worst 100 compounds. These have assigned -1 activity, which are not synthesizable according to the laboratory\n",
        "bottom100_mutate = list(sorted(sum([mloop.load(iteration_id=i) for i in range(mloop.n_iterations)], []), key=lambda k: k.activity))[0:100]\n",
        "show_molecules(bottom100_mutate)"
      ],
      "metadata": {
        "id": "wISdTyIam7Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can compute synthesizabiltiy before sending to the lab!\n",
        "from src.sas_score import compute_ertl_score\n",
        "compute_ertl_score(bottom100_mutate[0].smiles)"
      ],
      "metadata": {
        "id": "uTcMvQbxnU3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚒️ Exercise 3: Tune the warmup.\n",
        "\n",
        "Is is better to use longer or smaller warmup?"
      ],
      "metadata": {
        "id": "H2DCf-P5zBZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Run mutation loop\n",
        "mloop_it1 = MutateLoop(base_dir=\"mutate\", n_warmup_iterations=1, user_token=YOUR_TOKEN, target=\"GSK3β_server\")\n",
        "mutate_metrics_it1 = run(mloop_it1, purge=True, budget=1000, steps=10)\n",
        "\n",
        "mloop_it3 = MutateLoop(base_dir=\"mutate\", n_warmup_iterations=3, user_token=YOUR_TOKEN, target=\"GSK3β_server\")\n",
        "mutate_metrics_it3 = run(mloop_it3, purge=True, budget=1000, steps=10)\n",
        "\n",
        "# 5. Plot metrics using matplotlib\n",
        "plt.plot([i*100 for i in range(len(mutate_metrics_it3))],\n",
        "          [m['top10'] for m in mutate_metrics_it3], linewidth=4, label=\"mutate (it=3)\")\n",
        "plt.plot([i*100 for i in range(len(mutate_metrics_it1))],\n",
        "          [m['top10'] for m in mutate_metrics_it1], linewidth=4, label=\"mutate (i=1)\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "plt.xlabel('N_compounds')\n",
        "plt.ylabel('top10')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8tl9qOUi2tWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3: Machine Learning To Select Compounds More Efficiently\n"
      ],
      "metadata": {
        "id": "hmkpUU3-fucD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 📝 Automate the process\n",
        "\n",
        "Your reports drew the attention of stakeholders, and now the company asks you if you can make more accurate predictions, as many compounds end up inactive after testing in the laboratory. Adding machine Learning is a natural idea.\n",
        "\n",
        "Good luck!"
      ],
      "metadata": {
        "id": "zDK1fqYzg8u8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SknsnpZai4WP"
      },
      "source": [
        "### ⚒️ Exercise 4: Achieve meaningful correlation in molecular property prediction\n",
        "\n",
        "We will build a simple QSAR model based on the compounds that we tested in our previous experiment. In your other projects, you could also use publicly available data. Databases such as ChEMBL offer a lot of activity data gathered from various online sources.\n",
        "\n",
        "In the following experiment, we will use Morgan fingerprints to encode molecules. We will use them as an input to a random forest model that predicts the experimental activity. After training this model, we can use it to predict activity without paying for performing biochemical testing in a wet lab.\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/molecule-one/mlinpl-23-workshops/blob/main/assets/lab2.png?raw=true\" width=\"400px\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt8xbzXVi4WP"
      },
      "outputs": [],
      "source": [
        "# Let's load all mutated compounds\n",
        "mutate_cmpds = sum([mloop.load(iteration_id=i) for i in range(mloop.n_iterations)], [])\n",
        "\n",
        "# And build dataset\n",
        "data = pd.DataFrame({\n",
        "    'activity': [mol.activity for mol in mutate_cmpds],\n",
        "    'smiles': [mol.smiles for mol in mutate_cmpds],\n",
        "    'synthesizability': [mol.synth_score for mol in mutate_cmpds],\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cUwWjS4i4WP"
      },
      "outputs": [],
      "source": [
        "# We need to featurize compounds\n",
        "from rdkit.Chem import AllChem\n",
        "import numpy as np\n",
        "\n",
        "def calculate_fingerprint(smiles: str) -> np.ndarray:\n",
        "    ### TODO: compute a fingerprint\n",
        "    return ...\n",
        "\n",
        "data['fingerprint'] = data.smiles.apply(calculate_fingerprint)\n",
        "data = data[data['activity']>=0]\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aY-m3b9oi4WP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "41f0a9a0-58a3-4e35-ba2a-2cfa9ae324ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Assuming data is already loaded\n",
        "X_data, y_data = np.stack(data['fingerprint']), data.activity\n",
        "\n",
        "# Split the data into training and testing sets with a given proportion, for example, 80% for training and 20% for testing.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "y6s8vPqEi4WP"
      },
      "outputs": [],
      "source": [
        "df_preds = pd.DataFrame({'preds': model.predict(X_test), 'labels': y_test})\n",
        "corr = df_preds.corr('spearman').iloc[1, 0]\n",
        "print(\"ρ = \", corr)\n",
        "sns.scatterplot(data=df_preds, x='preds', y='labels')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert corr > 0.8"
      ],
      "metadata": {
        "id": "_O5sw9kUoVD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3XRFWFli4WQ"
      },
      "source": [
        "### Optional: Graph neural networks\n",
        "\n",
        "You can also use graph neural networks.\n",
        "\n",
        "<img src=\"https://github.com/molecule-one/mlinpl-23-workshops/blob/main/assets/lab3.png?raw=true\" width=\"400px\" />"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Aw0gOwKZemv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "el6CsXj-i4WQ"
      },
      "outputs": [],
      "source": [
        "def one_of_k_encoding(x, allowable_set):\n",
        "    if x not in allowable_set:\n",
        "        raise ValueError(\"input {0} not in allowable set{1}:\".format(\n",
        "            x, allowable_set))\n",
        "    return list(map(lambda s: x == s, allowable_set))\n",
        "\n",
        "\n",
        "def one_of_k_encoding_unk(x, allowable_set):\n",
        "    if x not in allowable_set:\n",
        "        x = allowable_set[-1]\n",
        "    return list(map(lambda s: x == s, allowable_set))\n",
        "\n",
        "\n",
        "def featurize_graph(smiles: str):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    A = np.zeros((mol.GetNumAtoms(), mol.GetNumAtoms()))\n",
        "    for bond in mol.GetBonds():\n",
        "      ### TODO: Add bonds to the adjacency matrix\n",
        "      ...\n",
        "\n",
        "    nodes = []\n",
        "    for atom in mol.GetAtoms():\n",
        "        ### TODO: Improve the atom encoding suggested below\n",
        "        results = one_of_k_encoding_unk(\n",
        "            atom.GetSymbol(),\n",
        "            ['C', 'O', 'N', 'Cl', 'F', 'S', '']\n",
        "        )\n",
        "        nodes.append(results)\n",
        "    X = np.array(nodes).astype(float)\n",
        "\n",
        "    return X, A"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, A = featurize_graph('c1ccccc1')\n",
        "assert X.shape[0] == 6\n",
        "assert A.shape == (6, 6)"
      ],
      "metadata": {
        "id": "DCjuDewCg01M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_graphs(batch):\n",
        "  X_all = []\n",
        "  A_all = []\n",
        "  for data in batch:\n",
        "    X, A = featurize_graph(data.smiles)\n",
        "    X_all.append(X)\n",
        "    A_all.append(A)\n",
        "  max_size = max([A.shape[0] for A in A_all])\n",
        "  A_padded = np.zeros((max_size * len(X_all), max_size))\n",
        "  for i, A in enumerate(A_all):\n",
        "    A_padded[i * max_size:i * max_size + A.shape[0], 0:A.shape[0]] = A\n",
        "  X_padded = np.zeros((max_size * len(X_all), X_all[0].shape[1]))\n",
        "  for i, X in enumerate(X_all):\n",
        "    X_padded[i * max_size:i * max_size + X.shape[0], :] = X\n",
        "  return (\n",
        "      torch.Tensor(X_padded),\n",
        "      torch.Tensor(A_padded),\n",
        "      torch.Tensor([data.activity for data in batch]),\n",
        "  )"
      ],
      "metadata": {
        "id": "CfVhAy4PhyhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [cmpd for cmpd in mutate_cmpds if cmpd.activity >= 0]"
      ],
      "metadata": {
        "id": "wCZ7Xn5w6hGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train, data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "train_loader = DataLoader(\n",
        "    data_train,\n",
        "    batch_size=4,\n",
        "    collate_fn=collate_graphs,\n",
        "    shuffle=True,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    data_test,\n",
        "    batch_size=4,\n",
        "    collate_fn=collate_graphs,\n",
        "    shuffle=False,\n",
        ")"
      ],
      "metadata": {
        "id": "1AW0LWpetcZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def mean_pool(X, batch_size):\n",
        "  pool = X.view(batch_size, -1, X.shape[1])\n",
        "  return pool.mean(dim=1)\n",
        "\n",
        "class GCNLayer(torch.nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super().__init__()\n",
        "    self.W = torch.nn.parameter.Parameter(torch.empty((in_features, out_features)))\n",
        "    torch.nn.init.kaiming_uniform_(self.W, a=math.sqrt(5))\n",
        "\n",
        "  def forward(self, X, A):\n",
        "    size = A.shape[1]\n",
        "    X_new = []\n",
        "    A = A.view(-1, size, size)\n",
        "    X = X.view(-1, size, X.shape[1])\n",
        "    for adj, x in zip(A, X):\n",
        "      ### TODO: Implement graph convolution\n",
        "      X_new.append(...)\n",
        "    return torch.concatenate(X_new)\n",
        "\n",
        "class GraphNeuralNetwork(torch.nn.Module):\n",
        "  def __init__(self, hidden_size, input_size=7):\n",
        "    super().__init__()\n",
        "    self.gcn1 = GCNLayer(in_features=input_size, out_features=hidden_size)\n",
        "    self.gcn2 = GCNLayer(in_features=hidden_size, out_features=hidden_size)\n",
        "    self.gcn3 = GCNLayer(in_features=hidden_size, out_features=hidden_size)\n",
        "    self.linear = torch.nn.Linear(in_features=hidden_size, out_features=1)\n",
        "\n",
        "  def forward(self, batch):\n",
        "    ### TODO: Improve the architecture suggested below\n",
        "    X, A, y = batch\n",
        "    batch_size = len(y)\n",
        "    X = F.relu(self.gcn1(X, A))\n",
        "    X = F.relu(self.gcn2(X, A))\n",
        "    X = F.relu(self.gcn3(X, A))\n",
        "    X = mean_pool(X, batch_size)\n",
        "    y = self.linear(X)\n",
        "    return y"
      ],
      "metadata": {
        "id": "M58iqndTuAHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZgFnHVui4WQ"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "def train(train_loader):\n",
        "    # hyperparameters definition\n",
        "    hidden_size = 32\n",
        "    epochs = 10\n",
        "    learning_rate = 0.0001\n",
        "\n",
        "    # model preparation\n",
        "    model = GraphNeuralNetwork(hidden_size)\n",
        "    model.train()\n",
        "\n",
        "    # training loop\n",
        "    optimizer = ... ### TODO: define an optimizer\n",
        "    loss_fn = ...  ### TODO: define a loss function\n",
        "    for epoch in trange(1, epochs + 1, leave=False):\n",
        "        for data in tqdm(train_loader, leave=False):\n",
        "            y = data[2]\n",
        "            model.zero_grad()\n",
        "            preds = model(data)\n",
        "            loss = loss_fn(preds, y.reshape(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return model\n",
        "\n",
        "\n",
        "def predict(model, test_loader):\n",
        "    # evaluation loop\n",
        "    preds_batches = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader):\n",
        "            preds = model(data)\n",
        "            preds_batches.append(preds.cpu().detach().numpy())\n",
        "    preds = np.concatenate(preds_batches)\n",
        "    return preds\n",
        "\n",
        "\n",
        "# training\n",
        "model = train(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_preds = pd.DataFrame({\n",
        "    'preds': predict(model, test_loader).flatten(),\n",
        "    'labels': [cmpd.activity for cmpd in data_test],\n",
        "})\n",
        "corr = df_preds.corr('spearman').iloc[1, 0]\n",
        "print(\"ρ = \", corr)\n",
        "sns.scatterplot(data=df_preds, x='preds', y='labels')"
      ],
      "metadata": {
        "id": "gRYOaIhjuTyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert corr > 0.75"
      ],
      "metadata": {
        "id": "Y264hkoxE8yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚒️ Exercise 5: Machine Learning Based Loop"
      ],
      "metadata": {
        "id": "K7u1-zvAgBD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize a base loop that mutates compounds based on the input candidates\n",
        "base_loop = MutateLoop(\n",
        "    base_dir='mlloop',\n",
        "    n_warmup_iterations=3,\n",
        "    user_token=YOUR_TOKEN,\n",
        "    target='GSK3β_server',\n",
        ")"
      ],
      "metadata": {
        "id": "aAXXV2HR1bo9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b6c7ad75-f027-43de-a372-ad33fd601754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n",
            "Loading...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[17:56:06]\u001b[0m\u001b[2;36m \u001b[0mSaving results to mlloop.                                                                  \u001b]8;id=362803;file:///content/mlinpl-23-workshops/src/al_loop.py\u001b\\\u001b[2mal_loop.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=774785;file:///content/mlinpl-23-workshops/src/al_loop.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:56:06] </span>Saving results to mlloop.                                                                  <a href=\"file:///content/mlinpl-23-workshops/src/al_loop.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">al_loop.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///content/mlinpl-23-workshops/src/al_loop.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Implement active learning loop that mutates compounds and filters the candidates using ML predictive models\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class MLLoop(Loop):\n",
        "    \"\"\"\n",
        "    Your final implementation of the experimental loop.\n",
        "\n",
        "    The algorithm you implement in the `propose_candidates` method will be repeated\n",
        "    several times to iteratively improve your candidates.\n",
        "\n",
        "    The molecules will be sent to the official lab endpoint with a LIMITED NUMBER OF REQUESTS,\n",
        "    so use this code wisely and care for the synthesizability of your compounds!\n",
        "    \"\"\"\n",
        "    def __init__(self, base_dir: Path, base_loop: Loop, n_warmup_iterations: int=1, user_token=None, target=\"DRD2\"):\n",
        "        self.base_loop = base_loop\n",
        "        self.n_warmup_iterations = n_warmup_iterations\n",
        "        super().__init__(base_dir, user_token, target)\n",
        "\n",
        "    def _featurize(self, smi: List[str]) -> np.ndarray:\n",
        "        # START SOLUTION\n",
        "        mols = [Chem.MolFromSmiles(s) for s in smi]\n",
        "        fps = [AllChem.GetMorganFingerprintAsBitVect(m, 2, 2048) for m in mols]\n",
        "        X = []\n",
        "        for fp in fps:\n",
        "            arr = np.zeros((1,))\n",
        "            DataStructs.ConvertToNumpyArray(fp, arr)\n",
        "            X.append(arr)\n",
        "        return np.array(X)\n",
        "        # END SOLUTION\n",
        "\n",
        "    def _split(self, X, y, smi) -> ...:\n",
        "        X_temp, X_test, y_temp, y_test, smi_temp, smi_test = \\\n",
        "            train_test_split(X, y, smi, test_size=0.3, random_state=42)\n",
        "        X_train, X_valid, y_train, y_valid, smi_train, smi_valid = \\\n",
        "            train_test_split(X_temp, y_temp, smi_temp, test_size=0.3, random_state=42)\n",
        "        return X_train, X_valid, X_test, y_train, y_valid, y_test, smi_train, smi_valid, smi_test\n",
        "\n",
        "    def _train_model(self, previous_results: List[LeadCompound]):\n",
        "        \"\"\"Trains models and assigns to ._model variable.\"\"\"\n",
        "        previous_results = [c for c in previous_results if c.activity != -1]\n",
        "        if len(previous_results) == 0:\n",
        "            raise ValueError(\"No previous results to train on (excluded activity = -1). Perhaps your \"\n",
        "                             \"base loop proposes nonsynthetizable compounds?\")\n",
        "        console.log(f\"Retraining model on {len(previous_results)} compounds.\")\n",
        "        smi = [c.smiles for c in previous_results]\n",
        "        X = self._featurize(smi)\n",
        "        y = np.array([c.activity for c in previous_results])\n",
        "        y = y > np.median(y) # convert to binary. loses information naturally.\n",
        "\n",
        "        console.log(f\"Shapes: X {X.shape}, y {y.shape}\")\n",
        "\n",
        "        # split using sklearn\n",
        "        X_train, X_valid, X_test, y_train, y_valid, y_test, smi_train, smi_valid, smi_test = self._split(X, y, smi)\n",
        "\n",
        "        console.log(f\"Training set size: {len(X_train)}\")\n",
        "        console.log(f\"Validation set size: {len(X_valid)}\")\n",
        "        console.log(f\"Test set size: {len(X_test)}\")\n",
        "        console.log(f\"Training set activity mean: {np.mean(y_train)}\")\n",
        "        console.log(f\"Proceeding to training Random Forest\")\n",
        "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        rf.fit(X_train, y_train)\n",
        "\n",
        "        self._model = rf\n",
        "\n",
        "    def _select_top_N(self, candidates: List[LeadCompound], n_select: int) -> List[LeadCompound]:\n",
        "        \"\"\"Ranks candidates by their predicted activity.\"\"\"\n",
        "        X_test = self._featurize([c.smiles for c in candidates])\n",
        "        y_pred = self._model.predict_proba(X_test)\n",
        "        if y_pred.ndim == 2:\n",
        "            y_pred = y_pred[:, -1]\n",
        "        return [c for _, c in sorted(zip(y_pred, candidates), reverse=True, key=lambda a: a[0])][:n_select]\n",
        "\n",
        "    def propose_candidates(self, n_candidates: int) -> List[LeadCompound]:\n",
        "        if self.n_iterations < self.n_warmup_iterations:\n",
        "            return self.base_loop.propose_candidates(n_candidates)\n",
        "\n",
        "        previous_results: List[LeadCompound] = self.load()\n",
        "        self._train_model(previous_results)\n",
        "        new_candidates = self.base_loop.propose_candidates(10 * n_candidates)\n",
        "        smi = [c.smiles for c in new_candidates]\n",
        "        smi = list(set(smiles))\n",
        "        new_candidates = [LeadCompound(smiles=smiles) for smiles in set(smi)]\n",
        "        return self._select_top_N(new_candidates, n_candidates)"
      ],
      "metadata": {
        "id": "NQD6k7Fs6oon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlloop = MLLoop(\n",
        "    base_dir=\"mlloop\",\n",
        "    base_loop=base_loop,\n",
        "    user_token=YOUR_TOKEN,\n",
        "    target=\"GSK3β_server\",\n",
        ")\n",
        "ml_metrics = run(mlloop, purge=True)\n",
        "\n",
        "# 5. Plot metrics using matplotlib\n",
        "plt.plot([i*100 for i in range(len(ml_metrics))],\n",
        "          [m['top10'] for m in ml_metrics], linewidth=4, label=\"ML\")\n",
        "plt.plot([i*100 for i in range(len(mutate_metrics_it3))],\n",
        "          [m['top10'] for m in mutate_metrics_it3], linewidth=4, label=\"mutate (it=3)\")\n",
        "plt.plot([i*100 for i in range(len(mutate_metrics_it1))],\n",
        "          [m['top10'] for m in mutate_metrics_it1], linewidth=4, label=\"mutate (i=1)\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "plt.xlabel('N_compounds')\n",
        "plt.ylabel('top10')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j9Vopfx46sh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4: Finding drugs for all targets\n",
        "\n",
        "The final part of the workshop is to find miracle drugs for DRD2 and JNK3 targets.\n",
        "\n",
        "Some tips:\n",
        "\n",
        "1. Pay attention to warmup.\n",
        "2. Pay attention to synthesizability. You can compute synthesizabiltiy before sending to the lab!\n",
        "\n",
        "```\n",
        "from src.sas_score import compute_ertl_score;\n",
        "compute_ertl_score(bottom100_mutate[0].smiles)```\n",
        "\n",
        "3. Pay attention to whether you can trust your model (e.g. you might want to select very confident prediction if your model is calibrated)."
      ],
      "metadata": {
        "id": "gD74XjwI1cAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "8L3eBMu1gOun"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": [
          "# Experimental\n"
        ]
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Nry0TOx8i4WL",
        "RdexFKami8rg",
        "gD74XjwI1cAv"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}